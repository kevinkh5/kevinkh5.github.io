---
title: "[Pandas] 판다스 자주 사용하는 코드(계속 업데이트중)"
author: baduk
date: 2024-11-17 15:38:00 +0900
categories: [Framework, Pandas]
tags: [Pandas]
---
## **파일관련 (load & save)**

### 엑셀 파일 저장
```python
with pd.ExcelWriter('엑셀파일.xlsx') as writer:  
    df1.to_excel(writer, sheet_name='sheet1', index = False)
    df2.to_excel(writer, sheet_name='sheet2', index = False)
```

### 엑셀 파일 읽기
```python
import pandas as pd
# 엑셀 파일 읽기
file_path = '엑셀파일.xlsx'  # 읽어올 파일 경로
df = pd.read_excel(file_path, sheet_name='sheet1')  # 특정 시트 읽기 (생략하면 첫 번째 시트)
```

### CSV save & load
```python
import pandas as pd
#저장 
df.to_csv('csv파일.csv', index=False, encoding='utf-8-sig')
# CSV 파일 로드
df = pd.read_csv('csv파일.csv')
# CSV 파일 로드하다 에러나면 아래꺼로!
df = pd.read_csv('test_error.csv', lineterminator='\n')
```

### load CSV -> JSON -> TUPLE(SQL)
```python
import pandas as pd
df = pd.read_csv('csv파일.csv')
json_result = df.to_json(orient='records', force_ascii=False)
json_result = json.loads(json_result)
results = [(0, result['col1'], result['col2'], result['col3'], result['col3']) for result in json_result]
```

### DB에서 가져온 튜플형식의 데이터를 데이터프레임으로 변환
```python
cursor = connection.cursor()

sql = """
select *
from DB_TABLE
"""
cursor.execute(sql)
columns = [item[0] for item in cursor.description] # 칼럼 가져오기
Data = pd.DataFrame(cursor.fetchall(),columns=columns)
cursor.close()
```

## **데이터 타입 변환**

### df(csv) -> json 변환
```python
json_result = df.to_json(orient='records', force_ascii=False)
# orient='records'로 해줘야 [{"col1":1,"col2":2},{"col1":3,"col2":4}]
# 의도한대로 json형태의 데이터로 변환 가능
# force_ascii를 False로 둬야 비ASCII 문자를 그대로 사용하여, 가독성 높일 수 있음
json_result = json.loads(json_result)
```

### json -> csv 변환
```python
df = pd.DataFrame(json_variable)
```

## **전처리 관련**

### row 이터레이션
```python
import pandas as pd

# 예시 데이터프레임 생성
data = {
    'video_id': [1, 2, 3],
    'title': ['Video A', 'Video B', 'Video C'],
    'views': [100, 200, 300]
}
df = pd.DataFrame(data)

# DataFrame의 각 행을 반복
for index, row in df.iterrows():
    # 각 행의 데이터에 접근
    print(f"Index: {index}, Video ID: {row['video_id']}, Title: {row['title']}, Views: {row['views']}")
```

### row 추가
```python
columns = ['video_id', 'title', 'result']
result_df = pd.DataFrame(columns=columns) # 데이터프레임 만들어서
new_row = pd.DataFrame([{'video_id':video_id, 'title': title, 'result': result}]) # 추가할 row를 만들어서
result_df = pd.concat([result_df, new_row], ignore_index=True) # 합치기
```

### row 수정
```python
for index, row in df.iterrows():
    df.at[index, 'new_col'] = 'new_val'
```

### 중복된 row를 지우고 싶을 때
```python
df = df.drop_duplicates()
# 
```

### 중복된 column을 지우고 싶을 때
```python
df = df_filtered.T.drop_duplicates().T
# .T는 데이터프레임의 전치(transpose)를 의미
# 
```

### 데이터 프레임 붙이기
```python
df_combined = pd.concat([df1, df2], axis=1)
# axis를 1로 주면 좌우로 붙이고, 0으로 주면 위 아래로 붙임
```

### 데이터 프레임 칼럼 이름 바꾸기
```python
# 칼럼 이름 변경
df.rename(columns={'id': 'new_id', 'title': 'new_title'}, inplace=True)
```

### 특정 칼럼만 남기기
```python
# 남기고 싶은 칼럼 목록
columns_to_keep = ['video_id', 'title']
# 특정 칼럼만 남기고 나머지 제거
df_filtered = df[columns_to_keep]
```

### 특정 칼럼만 지우기
```python
# 특정 칼럼 제거
df_filtered = df_filtered.drop(columns=['col1','col2'])
```

### 특정 칼럼을 맨 왼쪽으로 보내기
```python
df = df[['칼럼'] + [col for col in df.columns if col != '칼럼']]
```

### 리스트 형식의 값으로 들어가는 칼럼 값에서 괄호 제거(apply 메소드 및 람다 활용)
```python
df['col1'] = df['col1'].apply(lambda x: ', '.join(x))
```

### 기존 칼럼 더한 값을 새로운 칼럼으로 추가
```python
import pandas as pd

# 예제 데이터프레임
data = {
    'A': [10, 20, 30],
    'B': [1, 2, 3]
}
df = pd.DataFrame(data)

# 두 칼럼의 연산 결과를 새로운 칼럼 'C'에 추가
df['C'] = df['A'] + df['B']  # 예: A와 B의 합
print(df)
```

### sort
```python
sorted_df = df.sort_values(by='Count', ascending=False)
```

### sum
```python
total_sum = df['Count'].sum()
```

### ratio
```python
sm = df['Count'].sum()
df['Ratio'] = ((df['Count'] / sm).round(4))*100 # 퍼센트 변환
```

### left join
```python
df_join = pd.merge(df1,df2, on = 'col1', how = 'left')
```

### group by
```python
df.groupby('col1_id')['col1_id'].count()
# col1_id로 그룹바이 후, col1_id의 개수 구하기
```

```python
# 그룹바이후 구한 카운트를 다시 칼럼으로 넣고 싶으면 아래 코드 사용
df['col1_count'] = df.groupby('col1_id')['col1_id'].transform('count')
```
**count말고도 가능한 연산들**
```script
'mean': 그룹의 평균값
'sum': 그룹의 합계
'min': 그룹의 최솟값
'max': 그룹의 최댓값
'std': 그룹의 표준편차
'var': 그룹의 분산
'median': 그룹의 중앙값
'nunique': 그룹의 고유값 개수
grouped.transform(lambda x: x.astype(int).max()) # 람다 써서 하는 방법도 있음
```

## **데이터 체크 관련**

### nan 체크
```python
if pd.isna(value):
    value = "" # NaN 이면 ""으로 바꾸는 코드
```

### 특정 조건에 맞는 데이터 보기
```python
filtered_rows = df[(df['title'] == '') & (df['description'].notna())]
# title이 ''이고, description이 Nan이 아닌것의 개수
```

### 특정 조건에 따른 개수 구하기
```python
count_not_empty_strings = df[df['title'] != ''].shape[0] # ''값이 아닌것의 개수
not_nan_count = df['title'].notna().sum() # NaN이 아닌것의 개수
nan_count = df['title'].isna().sum()
```

### 특정 키로 접근 할 수 있는 딕셔너리로 바꾸기
```python
unique_dict = {row['video_id']: row for index, row in df.iterrows()}
unique_dict_for_product_list = {row['video_id']: row for index, row in df.iterrows() if row['video_id'] in video_id_list} # 조건 걸기
```

### 특정 리스트에 있는 값을 포함한 Row만 뽑기
```python
# List of values to filter by
filter_list = ['Food', 'Electronics']
# Filter rows where 'Category' contains values in filter_list
filtered_df = df[df['Category'].isin(filter_list)]
```

### 특정 문자열 값을 포함한 Row만 뽑기
```python
import pandas as pd
# 예제 데이터프레임
data = {
    "Comment": ["I love Python", "Python is great", "I prefer Java", "No comment"]
}
df = pd.DataFrame(data)
# 'Comment' 열에 'Python'이 포함된 행 필터링
filtered_df = df[df["Comment"].str.contains("Python", na=False)]
```

### 특정 값을 가진 Row빼고 뽑기
```python
df_filtered = df[df['col1'] != 'A']
```

## **데이터 이해하기(관계표현, 시각화)**

### Correlation (상관관계)과 히트맵 표현
```python
import seaborn as sns
import matplotlib.pyplot as plt

# 히트맵 그리기
df = df[['col1','col2','col3']]
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.xticks(rotation=15)
plt.show()
```

### 구글시트에 복붙해서 수치보기(칼럼이 많은 데이터프레임을 볼 때 유용)
```python
df.to_clipboard(index=False, sep='\t')
```

